# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KJwcCp1dwa8XP1Ro83Ey1Umycyu4p_ya
"""

import numpy as np
from keras import Sequential
from keras.callbacks import LearningRateScheduler, ModelCheckpoint,EarlyStopping, ReduceLROnPlateau, Callback
from keras.engine.saving import model_from_json
from keras.preprocessing.image import ImageDataGenerator
from keras.datasets import cifar100
from keras.layers import Dense, Conv2D, Flatten, Input, AvgPool2D,MaxPool2D,Dropout, BatchNormalization
from keras.optimizers import SGD
from keras.regularizers import l2
from keras.utils import to_categorical
from matplotlib import pyplot as plt
from keras.models import Model, Sequential
from sklearn.metrics import confusion_matrix,accuracy_score,log_loss
import seaborn as sns

# Model configuration
batch_size = 50
img_width, img_height, img_num_channels = 32, 32, 3
num_classes = 100
num_epochs = 100
# optimizer = Adam()
validation_split = 0.2
verbosity = 1
L2_DECAY_RATE = 0.0005
INIT_DROPOUT_RATE = 0.5

CIFAR100_LABELS_LIST = [
    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 
    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 
    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 
    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 
    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 
    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',
    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',
    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',
    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',
    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',
    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',
    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',
    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',
    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',
    'worm'
]

(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')
input_shape = (img_width, img_height, img_num_channels)

#lets look at the data:
print('X_train shape is: {} \n\
y_train shape is: {}'.format(X_train.shape,y_train.shape))
print()
print('X_test shape is: {} \n\
y_test shape is: {}'.format(X_test.shape,y_test.shape))

# print one sample from thr data:
# plt.imshow(X_train[0],cmap='binary')

# print the dta with the classification:
def plot_multiple_imgs(X,y,nrow=2,ncol=2,figsize=(13,7),preds=None,skip=0):
    fig = plt.figure(figsize=(32, 32))
    counter = 0
    showen_categories = []
    for i in range(10000):
      if(preds is None):
        if(CIFAR100_LABELS_LIST[y[i][0]] not in showen_categories ):
            showen_categories.append(CIFAR100_LABELS_LIST[y[i][0]])
            sub = fig.add_subplot(10, 10, counter + 1)
            sub.imshow(X[i], cmap='binary')
            sub.text(0.85, 0.1, CIFAR100_LABELS_LIST[y[i][0]], color='white', weight='bold',fontsize=20)
            counter = counter + 1
      else:
        if (preds[i] != y[i]):
          sub = fig.add_subplot(10, 10, counter+1)
          sub.imshow(X[i] ,cmap='binary')
          sub.text(0.85,0,"predict: " + CIFAR100_LABELS_LIST[preds[i]], color='red', weight='bold',fontsize=20)
          sub.text(0.85,35,"real: " + CIFAR100_LABELS_LIST[y[i][0]], color='green', weight='bold',fontsize=20)
          counter = counter + 1
      if(counter==100):
          break


# print one sample from each class of the train:
# plot_multiple_imgs(X_train,y_train,10,10,(12,8))

# Create the model
def create_model():
  model = Sequential()
  model.add(Conv2D(16,3,activation='relu', padding='same', input_shape=(32,32,3)))
  model.add(Dropout(0.2))
  model.add(MaxPool2D(pool_size=(2, 2)))
  # model.add(BatchNormalization())

  model.add(Conv2D(32,3,activation='relu', padding='same',))
  model.add(Dropout(0.2))
  model.add(MaxPool2D(pool_size=(2, 2)))
  # model.add(BatchNormalization())

  model.add(Conv2D(128,3,activation='relu', padding='same',))
  model.add(Dropout(0.2))
  model.add(MaxPool2D(pool_size=(2, 2)))
  # model.add(BatchNormalization())

  model.add(Conv2D(256,3,activation='relu', padding='same',))
  model.add(Dropout(0.2))
  model.add(MaxPool2D(pool_size=(2, 2)))
  # model.add(BatchNormalization())

  model.add(Flatten())
  model.add(Dense(num_classes, activation='softmax'))

  model.summary()
  return model

# print the plots of the results:
def visual_results(history):
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('Model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='upper left')
  plt.show()

  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='upper left')
  plt.show()


def save_model(model):
    model_json = model.to_json()
    with open("model_nocallback.json", "w") as json_file:
        json_file.write(model_json)
    model.save_weights("model_nocallback.h5")

def load_model():
    json_file = open('model_nocallback.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    loaded_model.load_weights("model_nocallback.h5")
    return loaded_model

#### TASK 2 ####

#### task 2.b: ####
callbacks_model = [EarlyStopping('val_loss', patience=20),
             ModelCheckpoint('cifar100Model_100e_keras.h5', save_best_only=True)]
# Compile the model
model_1 = create_model()
model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Fit data to model
history = model_1.fit(X_train,
                      to_categorical(y_train),
                      callbacks=callbacks_model,
                      validation_split=0.2,
                      shuffle=True,
                      epochs=20)

# load existing weights
# model_1.load_weights('cifar100Model_100e_keras.h5')

# Visualize history
visual_results(history)

# predict on test set
preds = model_1.predict(X_test)
predicts = np.argmax(preds, axis=1)

print(confusion_matrix(y_test,predicts))
print('model accuracy on test set is: {}%'.format(accuracy_score(y_test,predicts)*100))

# plot_multiple_imgs(X_test,y_test,10,10,(12,12),predicts,skip=200)
sns.heatmap(confusion_matrix(y_test,predicts),cmap='Greens',annot=True, fmt='d')
plt.xlabel('Prediction')
plt.ylabel('True label')
plt.title('CIFAR-100 Convolutional model \n classification results on test set')
plt.show()
print()

#### task 2.d ####

# normalized the data
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
mean_train = np.mean(X_train, axis = 0)
std_train = np.std(X_train, axis = 0)
X_train = (X_train-mean_train)/std_train
mean_test = np.mean(X_test, axis = 0)
std_test = np.std(X_test, axis = 0)
X_test = (X_test-mean_test)/std_test


model_2 = create_model()
model_2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

# create augmentation
datagen = ImageDataGenerator(rotation_range=15,
                                   width_shift_range=0.1,
                                   height_shift_range=0.1,
                                   shear_range=0.03,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                   fill_mode='reflect',
                                   data_format='channels_last')
datagen.fit(X_train)
history = model_2.fit_generator(datagen.flow(X_train, to_categorical(y_train), batch_size=128),
steps_per_epoch=len(X_train) / 128, epochs=100, validation_data = (X_train, to_categorical(y_train)))

# model_2.load_weights('cifar100Model3_100e_keras.h5')

# model_2 = load_model()
visual_results(history)
preds = model_2.predict(X_test)
predicts = np.argmax(preds, axis=1) 
print(confusion_matrix(y_test,predicts))
print('model accuracy on test set is: {}%'.format(accuracy_score(y_test,predicts)*100))
save_model(model_2)
# plot_multiple_imgs(X_test,y_test,10,10,(12,12),predicts,skip=200)
sns.heatmap(confusion_matrix(y_test,predicts),cmap='Greens',annot=True, fmt='d')
plt.xlabel('Prediction')
plt.ylabel('True label')
plt.title('CIFAR-100 Convolutional model \n classification results on test set')
plt.show()
print()


#### TASK 3 ####